# Use Cases, Humans in the Loop, and Other Sleights of Hand

Autor(es): Bridget C.E. Dooling  
Data: February 16, 2026  
Fonte: https://www.yalejreg.com/nc/use-cases-humans-in-the-loop-and-other-sleights-of-hand-by-bridget-c-e-dooling/

---

There are plenty of good use cases for AI in government decisionmaking, but sometimes we need to say no. It seems like it’s harder than it should be right now to say no.

The reasons are important, and they start with being clear about who is using AI for what. Who are the users? It’s not one category. There are multiple use cases, and multiple users. But for now we talk as though it’s one of each. That makes it hard to assess what is at stake. In a recent draft paper, I explore the use cases for agency use of AI in the rulemaking process, and how they map onto the goals and structure of notice-and-comment rulemaking. We should do similar work for other agency functions.

Second, AI systems are truly remarkable but they are not capable of making values-laden policy decisions. This is not a matter of what people think or what the market says. It’s about what the technology is for. It predicts patterns and generates outputs. It does not have the capacity to choose among values or to be accountable for those choices.

Third, we kid ourselves if we think that a “human in the loop” is more than an impoverished way to think about what agencies owe the public. The phrase is used like a talisman. It suggests that someone is watching. But a human can be “in the loop” and still not be exercising judgment. The human can be a mere signer. The human can be overworked and under-resourced. The human can defer to the system because it feels authoritative.

Fourth, sometimes “use cases” are sleights of hand. A use case can be a story that makes a project sound plausible and beneficial. It can be a sales pitch. It can also avoid the hard questions. Instead of saying, “Should we do this,” we say, “We can do this.” That’s not the same thing.

Finally, we can likely make great progress in regulatory policy by letting algorithms into our loop, not the other way around. AI can help with tasks that are genuinely well suited to automation. But we should not let it displace the human work of public reasoning and decisionmaking.

Bridget C.E. Dooling is Assistant Professor of Law at The Ohio State University.
