# Artificial Intelligence and Administrative Law: The UK’s Search for a New Framework

Autor(es): Joe Tomlinson; Brendan McGurk  
Data: February 16, 2026  
Fonte: https://www.yalejreg.com/nc/artificial-intelligence-and-administrative-law-the-uks-search-for-a-new-framework-by-joe-tomlinson-brendan-mcgurk/

---

This post is the eleventh contribution to Notice & Comment’s symposium on AI and the APA. For other posts in the series, click here.

The questions animating this symposium—how administrative law should adapt to the rise of artificial intelligence—are hardly confined to the United States. The United Kingdom, like many other jurisdictions, is grappling with the same core issues. The UK’s approach is distinctive: it has, at least until recently, largely resisted introducing a bespoke legal framework for AI, instead relying on existing laws and sector-by-sector regulatory guidance.

In March 2023, the UK government published a white paper, A pro-innovation approach to AI regulation. The paper set out five cross-cutting principles (safety, transparency, fairness, accountability, and contestability) and proposed that existing regulators—rather than a new AI regulator—should interpret and apply these principles within their sectors. This has often been described as a “light-touch” approach.

In practice, this means that AI-related governance is spread across multiple bodies and instruments. Some regulators, such as the Information Commissioner’s Office, have been active in producing guidance and enforcement. Others have been slower to respond.

The UK also has introduced some transparency initiatives. For example, the Algorithmic Transparency Recording Standard (ATRS) and the associated transparency register provide a mechanism for public bodies to record certain uses of algorithmic tools. The register includes, for instance:

- A tool used by the Ministry of Justice to help triage and prioritize citizen correspondence;
- A tool used by the Department for Work and Pensions to detect potential fraud and error;
- Tools used by the Home Office in immigration-related decisionmaking.

Yet despite these initiatives, there remains significant uncertainty about how existing administrative law principles will apply to AI-driven decisionmaking. UK public law doctrines such as procedural fairness, reasonableness, and proportionality can address some issues, but AI raises distinctive challenges: opacity, vendor control, evolving systems, and the possibility of systematic error at scale.

There is also relatively little case law to date in the UK. That is likely to change as AI becomes more embedded in state functions. Waiting for litigation, however, carries risks. High-profile failures in other jurisdictions illustrate what can go wrong. For example, Australia’s Robodebt scandal involved automated debt recovery and was ultimately found unlawful. The Netherlands’ SyRI system was struck down for violating human rights and privacy.

In light of these risks, there is increasing discussion in the UK about whether a more dedicated public law framework is needed. The Law Commission has been examining the issue, and has suggested that:

“[T]here may be a case for reform of the current legal framework to ensure that public law can adequately respond to the challenges posed by [AI] systems.”

Any move toward a new framework is likely to take time. In the meantime, UK courts and oversight bodies will have to apply existing doctrines to AI-related challenges, often with limited transparency into how systems function.

Joe Tomlinson is a Professor of Public Law at the University of York; Brendan McGurk is a Postdoctoral Research Fellow at the University of York.
