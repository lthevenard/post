# O “Simpósio sobre IA e o APA” do Yale Journal on Regulation: organizando um debate emergente

![Illustration: The "AI hand"](./assets/posts/2026-yale-symposium/cover.png)

<br>

A inteligência artificial virou uma palavra-chave política em muitas jurisdições, especialmente nos Estados Unidos. Nos debates atuais sobre o uso de IA na administração pública, ela é alternativamente apresentada—tanto por defensores quanto por críticos—como uma promessa de aumento de capacidade estatal ou como um atalho para automatizar funções públicas sem responsabilização.

Essa tensão deixou de ser abstrata. Ela agora está no coração da máquina cotidiana do Estado administrativo, moldando como pensamos sobre regulamentação, contratações públicas, fiscalização, gestão de benefícios e os inúmeros passos internos que antecedem (e moldam) decisões voltadas ao público.

Uma das razões pelas quais esse debate parece urgente é que o uso governamental de IA deixou de ser especulação: ele já acontece em diversas agências e costuma ser apresentado como resposta a restrições institucionais familiares—equipes reduzidas, grandes cargas de trabalho e intensa pressão (política e judicial) para justificar decisões por escrito.

Nesse contexto, o blog [Notice & Comment](https://www.yalejreg.com/nc/) do Yale Journal on Regulation lançou a série de textos “[Symposium on AI and the APA](https://www.yalejreg.com/topic/symposium-on-ai-and-the-apa/).” O objetivo do simpósio é criar um diálogo aberto sobre o que acontece quando a IA é usada para auxiliar procedimentos administrativos e funções públicas estruturadas pela Administrative Procedure Act (APA) nos Estados Unidos—um espaço “for AI skeptics, AI believers, and everyone in between” (para céticos, entusiastas e os indecisos) para discutir o presente e o futuro da governança diante de tecnologias de IA em rápida evolução.

Neste post, exploro alguns dos principais temas e ideias que vêm emergindo no simpósio até aqui. O objetivo é descritivo: organizar o debate, destacando onde os autores parecem convergir e onde as principais linhas de conflito jurídico estão ficando mais nítidas.

## 1. Um debate politicamente carregado

No texto de abertura da série, Bridget C.E. Dooling e Jordan Ascher chamam atenção para um padrão conhecido: quando surge uma ferramenta capaz de gerar texto plausível em escala, a tentação é tratá-la como um atalho pela burocracia—especialmente por procedimentos há muito criticados como lentos ou excessivamente onerosos. A introdução deles soa como um relato de campo do atual momento “AI-forward” da governança federal: a Casa Branca pedindo para “Accelerating Federal Use of AI”; o Department of Veterans Affairs usando IA como instrumento bruto para “munch” contratos; autoridades de defesa prometendo integração mais profunda de IA; agências oferecendo chatbots a servidores; a EPA dizendo que usará IA para facilitar a revisão de comentários públicos; e propostas ou reportagens mais ambiciosas (e mais controversas), como o plano do DOGE de usar IA para revogar metade de todas as regulações federais e notícias de que o Department of Transportation pode usar o Google Gemini para redigir regras. (Veja a introdução de Dooling & Ascher [aqui](https://www.yalejreg.com/nc/introduction-to-the-symposium-on-artificial-intelligence-and-the-administrative-procedure-act-by-bridget-c-e-dooling-jordan-ascher/).)

Esses exemplos importam não apenas porque sugerem adoção, mas porque refletem uma demanda política específica: fazer o Estado administrativo andar mais rápido. Na era Trump, essa demanda costuma ser expressa como uma mistura de retórica de inovação (“modernização”) e impaciência antiburocrática (“cortar burocracia”). A IA se torna atraente porque parece encurtar a distância entre uma decisão política e a publicação no *Federal Register*—isto é, entre uma escolha política e uma narrativa capaz de sobreviver ao escrutínio.

Ao mesmo tempo, a história não é apenas que “a tecnologia chegou”. A história também é sobre *o que se está pedindo que a IA faça*. Algumas das propostas e reportagens mais visíveis têm enquadrado a IA não apenas como uma forma de acelerar trabalho burocrático, mas como um meio de acelerar políticas de alto impacto—especialmente em contextos em que a velocidade, por si só, é um objetivo político (desregulamentação, revogação e implementação rápida de novas iniciativas). Tara Aida, por exemplo, usa a proposta do “AI Deregulation Decision Tool” do DOGE como ponto de partida e alerta contra tratar a IA como um solvente procedimental, capaz de dissolver as partes mais trabalhosas do processo de elaboração de normas (rulemaking) sem alterar a substância do que o APA busca proteger. (Ver [Aida](https://www.yalejreg.com/nc/ticking-the-boxes-ai-and-the-notice-and-comment-process-by-tara-aida/))

Aida também situa o apelo da IA em um clima intelectual mais amplo: críticas à “sobreprocedimentalização” do direito administrativo se tornaram mais comuns, fazendo a promessa de automação parecer—ao menos retoricamente—uma correção atrasada para um processo que muitos já consideram lento e formal demais. (Ver [Aida](https://www.yalejreg.com/nc/ticking-the-boxes-ai-and-the-notice-and-comment-process-by-tara-aida/))

É por isso que administrativistas estão prestando atenção: as perguntas difíceis não são sobre se agências podem usar um corretor ortográfico. Elas são sobre se agências podem usar IA para fazer o trabalho que o APA foi desenhado para obrigá-las a fazer—um trabalho que é tanto de julgamento quanto de papelada.

## 2. Divergência, consenso emergente e linhas de conflito mais nítidas

O “Symposium on AI and the APA” do Yale Journal on Regulation é um retrato útil do debate atual entre administrativistas nos Estados Unidos sobre usos de IA na administração pública. Ele é um bom ponto de entrada precisamente porque não fala com uma só voz. Os autores incluem acadêmicos e profissionais, e abordam o problema de ângulos diferentes: doutrinário, institucional, técnico e comparado.

Ainda assim, ao ler os textos publicados até aqui como parte da série, é possível perceber ao menos alguns **pontos de consenso emergente** entre os autores:

- **As exigências jurídicas básicas não desaparecem.** As exigências do APA de tomada de decisão fundamentada, atenção ao record (registro administrativo) e capacidade de responder a insumos juridicamente relevantes continuam definindo o piso, mesmo que agências usem novas ferramentas para cumpri-las. (Ver [Coglianese](https://www.yalejreg.com/nc/ai-taxi-drivers-and-administrative-law-by-cary-coglianese/) e [Jones & Ünel](https://www.yalejreg.com/nc/do-large-language-models-dream-of-the-administrative-procedure-act-by-jack-jones-burcin-unel/))
- **O contexto importa.** “Uso de IA por agências” não é uma coisa só. Usar IA para triagem de correspondência, para resumir comentários públicos, para pontuar propostas em compras públicas ou para rascunhar textos normativos envolve riscos distintos e aciona ganchos jurídicos distintos. (Ver [Orbea & Froude](https://www.yalejreg.com/nc/determining-the-reasonableness-of-regulating-with-ai-by-gilbert-orbea-emily-froude/) e [Tillipman](https://www.yalejreg.com/nc/abdicated-judgment-ai-tools-and-the-future-of-reasoned-decision-making-in-federal-procurement-by-jessica-tillipman/))
- **“Human in the loop” não é uma resposta completa.** Vários textos tratam a expressão como uma teoria de governança incompleta: ela pode sinalizar supervisão real, mas também pode virar um escudo retórico para chancelar decisões automaticamente. (Ver [Dooling](https://www.yalejreg.com/nc/use-cases-humans-in-the-loop-and-other-sleights-of-hand-by-bridget-c-e-dooling/) e [Ascher & Lewis](https://www.yalejreg.com/nc/toward-minimum-administrative-law-standards-for-agency-usage-of-ai-by-jordan-ascher-john-lewis/))

Para além desses acordos, o simpósio também esclarece as **linhas de conflito** que provavelmente moldarão a próxima rodada de debates jurídicos e de política pública sobre esse tema. Essas linhas de conflito são o foco da próxima seção.

## 3. Os debates que começam a se delinear

A seguir estão os principais temas que o simpósio ajuda a trazer para o foco. Cada tema é apresentado como um conjunto de perguntas—e, quando ajuda, como um diálogo entre autores que estão falando uns com os outros, contra os outros, ou simplesmente passando uns pelos outros.

### 3.1. “Tomada de decisão fundamentada” vs. “texto que soa fundamentado”

O direito administrativo muitas vezes trata a explicação escrita como um proxy do pensamento: agências devem “examinar os dados relevantes” e “articular uma explicação satisfatória”, e os tribunais revisam se as razões declaradas conectam o record à escolha.

O simpósio retorna repetidamente a um receio: a IA generativa pode **romper esse vínculo**. Se LLMs tornam a prosa plausível barata, fica mais fácil produzir documentos que *parecem* refletir uma tomada de decisão fundamentada sem, de fato, refletirem isso.

A analogia do “taxista” de Coglianese captura bem a intuição. LLMs podem entregar respostas confiantes e plausíveis—incluindo sobre questões técnicas de política pública—mas as exigências do APA não são satisfeitas apenas por plausibilidade. A disciplina do direito administrativo é justamente insistir em evidências, alternativas e uma cadeia defensável de fatos até a escolha de política. (Ver [Coglianese](https://www.yalejreg.com/nc/ai-taxi-drivers-and-administrative-law-by-cary-coglianese/))

Ascher e Lewis levam esse ponto adiante ao enfatizar que a “responsabilidade final” não pode ser terceirizada—especialmente quando se sabe que a ferramenta tem modos de falha (alucinações, viés, bajulação e limitações de contexto). Na forma como eles apresentam o problema, as exigências do APA relativas à apresentação de razões pressionam não apenas o *resultado substantivo*, mas também se a agência pode mostrar, de forma plausível, que seres humanos de fato engajaram com o material relevante, em vez de simplesmente chancelarem uma narrativa gerada por máquina. (Ver [Ascher & Lewis](https://www.yalejreg.com/nc/toward-minimum-administrative-law-standards-for-agency-usage-of-ai-by-jordan-ascher-john-lewis/))

Tillipman faz o mesmo ponto estrutural a partir de um contexto concreto—as compras públicas federais—onde decisores já precisam documentar compensações. A IA pode gerar documentação, mas a documentação pode se tornar performática se não estiver amarrada a um julgamento humano que possa ser defendido sob escrutínio. (Ver [Tillipman](https://www.yalejreg.com/nc/abdicated-judgment-ai-tools-and-the-future-of-reasoned-decision-making-in-federal-procurement-by-jessica-tillipman/))

E Dooling adiciona uma crítica institucional mais ampla: “human in the loop” pode virar uma forma de evitar a pergunta sobre o que, exatamente, humanos devem ao público em termos de julgamento carregado de valores. Se o humano é apenas signatário, o “loop” não está fazendo o trabalho que o direito administrativo assume que ele está fazendo. (Ver [Dooling](https://www.yalejreg.com/nc/use-cases-humans-in-the-loop-and-other-sleights-of-hand-by-bridget-c-e-dooling/))

### 3.2. O problema da “caixa-preta” — e por que correções técnicas podem não ser correções jurídicas

Uma das preocupações mais antigas sobre IA no governo é a opacidade: se nem o público nem a própria agência conseguem explicar como um sistema produziu um resultado, como esse sistema pode ser revisado, contestado ou confiável?

A contribuição de Elliot E.C. Ping foca em uma tentativa contemporânea de domar essa opacidade: a formulação de prompts com chain-of-thought. Na comunidade de IA, chain-of-thought costuma ser tratada como uma forma de fazer modelos “mostrarem o trabalho”. A cautela de Ping, lida sob a lente do direito administrativo, é que *mais explicação não é necessariamente melhor explicação*—porque o “raciocínio” pode ser instável, confabulado ou desconectado da base real do resultado. Em outras palavras, chain-of-thought pode criar uma **ilusão de transparência** em vez de um registro de razões reais. (Ver [Ping](https://www.yalejreg.com/nc/iterative-reasoning-arbitrary-results-chain-of-thought-prompt-engineering-for-apa-compliance-by-elliot-e-c-ping/))

Aqui, o simpósio começa a soar como um diálogo sobre o que “razões” afinal são sob o APA. O sistema jurídico se importa com razões porque elas deveriam ser (a) ancoradas no record, (b) estáveis o suficiente para revisão e (c) atribuíveis à agência no momento da decisão (e não inventadas depois como estratégia de litígio). Se sistemas de IA conseguem gerar justificativas plausíveis sob demanda, administrativistas precisam perguntar se as palavras na página ainda funcionam como evidência do processo decisório da agência.

### 3.3. Método, record e transparência: o que uma agência deveria ter de explicar sobre o uso de IA?

Uma das perguntas doutrinárias mais concretas do simpósio é metodológica: se uma agência usa IA de um modo que importa, **o que ela precisa explicar**?

Ascher e Lewis fazem uma analogia com debates de longa data nos EUA sobre o uso, por agências, de modelos quantitativos. Nesses contextos, agências precisam ser capazes de defender pressupostos e métodos quando desafiadas. O paralelo é simples: se ferramentas de IA estão moldando o que a agência faz (e não apenas formatando prosa), então agências deveriam ser capazes de explicar escolha de modelo, formulação de prompts, validação e limites. (Ver [Ascher & Lewis](https://www.yalejreg.com/nc/toward-minimum-administrative-law-standards-for-agency-usage-of-ai-by-jordan-ascher-john-lewis/))

Jones e Ünel oferecem um enquadramento pragmático que ao mesmo tempo estreita e aguça o problema. Eles sugerem que tribunais provavelmente continuarão focando se a regra final é suportada por evidências, responsiva a comentários significativos e coerente em sua face—em vez de rotineiramente “auditar” o uso interno de IA. Mas também sublinham que opacidade e bajulação criam vulnerabilidade real: se já há indícios de que o raciocínio da agência é raso ou inconsistente, a dependência de IA pode fazer a decisão parecer ainda menos ancorada em julgamento especializado. Eles também destacam que nem todo uso de IA é igual: um modelo controlado pela agência, treinado em dados curados, levanta perguntas de responsabilização diferentes de um modelo público, de uso geral, treinado em fontes não controladas. (Ver [Jones & Ünel](https://www.yalejreg.com/nc/do-large-language-models-dream-of-the-administrative-procedure-act-by-jack-jones-burcin-unel/))

A contribuição de Orbea e Froude pode ser lida como uma forma de operacionalizar isso. Eles perguntam como poderia ser um controle de “razoabilidade” quando há IA envolvida, propondo que o escrutínio plausivelmente varia com (i) a natureza da autoridade (quanto de discricionariedade carregada de valores está em jogo), (ii) o papel que a IA desempenha (consultivo vs. decisivo) e (iii) as apostas e consequências. Esse enquadramento reforça um ponto central deste texto: governança de IA não é “tamanho único”; ela tende a ser **específica por caso de uso** e **estratificada por risco**. (Ver [Orbea & Froude](https://www.yalejreg.com/nc/determining-the-reasonableness-of-regulating-with-ai-by-gilbert-orbea-emily-froude/))

Por fim, o texto comparado de Tomlinson e McGurk destaca que “disclosure” (divulgação/transparência) não é apenas uma obsessão americana. As iniciativas britânicas de transparência algorítmica lembram que sistemas democráticos estão experimentando com registros e padrões de registro para tornar IA no setor público mais legível—ainda que essas iniciativas permaneçam parciais e contestadas. (Ver [Tomlinson & McGurk](https://www.yalejreg.com/nc/artificial-intelligence-and-administrative-law-the-uks-search-for-a-new-framework-by-joe-tomlinson-brendan-mcgurk/))

### 3.4. Quem deveria escrever as novas regras: tribunais, agências ou algo intermediário?

Mesmo que todos concordassem que a IA exige novas salvaguardas, há uma disputa de segunda ordem sobre **autoria institucional**: quem deve definir essas salvaguardas?

Adam Crews argumenta contra a expectativa de que tribunais inventem um novo “direito administrativo da IA” por meio de exigências procedimentais feitas por juízes. O alerta dele é doutrinário e político: *Vermont Yankee* limita criatividade judicial em matéria procedimental, e a postura atual da Suprema Corte torna instável a inovação ambiciosa guiada por tribunais. Na leitura de Crews, o caminho mais plausível é que agências desenvolvam práticas—políticas, rotinas de documentação, normas de divulgação—que depois possam virar uma espécie de “common law administrativo” reconhecido por tribunais como linha de base de razoabilidade. O ACUS, nessa história, aparece como uma instituição coordenadora importante. (Ver [Crews](https://www.yalejreg.com/nc/agencies-not-courts-should-develop-administrative-common-law-for-ai-by-adam-crews/))

Esse tema volta ao debate sobre método/record: na medida em que o uso de IA se normalize, tribunais podem, gradualmente, tratar certos tipos de documentação ou divulgação como a linha de base esperada. A pergunta implícita do simpósio é se essa linha de base surgirá por pressão de litígios, por orientação do Executivo, por coordenação entre agências ou por alguma combinação disso.

### 3.5. Pontos de tensão específicos por aplicação: onde o APA atinge a IA primeiro (e com mais força)

Se os temas anteriores são sobre doutrina e instituições, o simpósio também deixa claro que o debate “IA e APA” não ficará abstrato. Ele provavelmente se desenvolverá em torno de **ambientes administrativos específicos**—porque esses ambientes expõem modos de falha distintos e acoplam ganchos jurídicos distintos.

**Notice-and-comment como “tick-the-box.”** O texto de Aida foca no § 553 e no processo de notice-and-comment. A preocupação dela não é apenas que a IA seja usada para redigir notices ou respostas, mas que ela possa transformar o record escrito em um proxy oco: respostas mais detalhadas podem coexistir com menos engajamento humano, menos investigação e menos abertura genuína à crítica. O alerta adicional é que a formulação do prompt pode embutir a conclusão (“rejeite a crítica”) de um modo que produza sistematicamente uma mentalidade fechada. Essa é, talvez, a formulação mais clara, no simpósio, de uma preocupação com “legitimidade procedimental”: a IA pode fazer o processo parecer mais responsivo enquanto o torna menos deliberativo. (Ver [Aida](https://www.yalejreg.com/nc/ticking-the-boxes-ai-and-the-notice-and-comment-process-by-tara-aida/))

**Compras públicas e o “paradoxo da documentação.”** O exemplo de Tillipman em compras públicas mostra como a IA pode gerar pontuações extensas e narrativas que aparentam satisfazer exigências de documentação enquanto enfraquecem a capacidade da agência de explicar compensações sob escrutínio. Em compras públicas, a assinatura do decisor importa; se a IA reduz a assinatura a uma formalidade, contestações em processos de contratação podem virar um teste de se o direito administrativo aceitará julgamento moldado por máquina como “fundamentado”. (Ver [Tillipman](https://www.yalejreg.com/nc/abdicated-judgment-ai-tools-and-the-future-of-reasoned-decision-making-in-federal-procurement-by-jessica-tillipman/))

**Reforma regulatória e automação “útil”.** A contribuição de Reeve T. Bull é um contraponto útil às leituras mais distópicas. Em vez de tratar a IA como substituta da formulação de políticas, Bull imagina a IA como ferramenta para organizar o código regulatório—classificar obrigações, identificar onde a autoridade é frágil, evidenciar problemas de incorporation-by-reference e permitir revisão retrospectiva mais sistemática. Nessa moldura, a IA ajuda agências a enxergar o que já existe e a priorizar reformas, sem fingir que reforma é uma tarefa mecânica de deletar. (Ver [Bull](https://www.yalejreg.com/nc/ai-empowered-regulatory-reform-spreading-the-virginia-model-by-reeve-t-bull/))

Juntos, esses “pontos de pressão” sustentam uma afirmação organizadora mais ampla: muitas das disputas jurídicas que estão por vir terão menos a ver com se a IA é usada ou não e mais com **qual papel a IA desempenha** em um fluxo de trabalho administrativo específico—triagem, sumarização, recomendação, redação ou decisão—e como esse papel interage com as exigências do APA.

## Conclusão

Lido como um debate único, o simpósio sugere que o direito administrativo americano está entrando em uma nova fase—em que as questões centrais não são apenas sobre autoridade ou deferência, mas sobre a *produção de razões* e as *condições institucionais* sob as quais razões podem ser confiáveis.

O consenso emergente é modesto, mas significativo: a IA não anula o APA. Agências ainda serão julgadas por sua capacidade de conectar escolhas a evidências, responder a insumos significativos e assumir responsabilidade por suas decisões. Mas o simpósio também deixa claro por que o debate está esquentando: a IA generativa pode produzir, a baixo custo, os artefatos que o direito administrativo há muito tratou como evidência de deliberação. Se esse vínculo entre escrita e julgamento enfraquece, o sistema jurídico terá de decidir como reancorar a responsabilização—por divulgação, validação, construção de record, salvaguardas institucionais ou tudo isso junto.

O que torna o simpósio especialmente útil (e os próximos anos especialmente incertos) é que ele explicita intuições concorrentes que são ambas plausíveis:

- Por um lado, o APA pode ser visto como tecnologia-neutro: tribunais podem seguir aplicando testes conhecidos ao resultado final.
- Por outro, a mudança em como textos administrativos podem ser produzidos pode exigir novas expectativas sobre método, transparência e envolvimento humano—porque os antigos proxies de responsabilização podem deixar de funcionar.

Organizar o debate em torno desses temas não responde às perguntas difíceis. Mas ajuda a esclarecer o que muitos administrativistas americanos já tratam como a pauta real: decidir quando a IA é apenas uma ferramenta dentro do processo administrativo—e quando ela vira uma mudança estrutural que força o direito administrativo a repensar o que significa governar por razões.

## Posts do simpósio até o momento (para leitura adicional)

- Bridget C.E. Dooling & Jordan Ascher, “[Introduction to the Symposium on Artificial Intelligence and the Administrative Procedure Act](https://www.yalejreg.com/nc/introduction-to-the-symposium-on-artificial-intelligence-and-the-administrative-procedure-act-by-bridget-c-e-dooling-jordan-ascher/)” (Feb. 5, 2026)
- Cary Coglianese, “[AI, Taxi Drivers, and Administrative Law](https://www.yalejreg.com/nc/ai-taxi-drivers-and-administrative-law-by-cary-coglianese/)” (Feb. 6, 2026)
- Jordan Ascher & John Lewis, “[Toward Minimum Administrative Law Standards for Agency Usage of AI](https://www.yalejreg.com/nc/toward-minimum-administrative-law-standards-for-agency-usage-of-ai-by-jordan-ascher-john-lewis/)” (Feb. 6, 2026)
- Jack Jones & Burçin Ünel, “[Do Large Language Models Dream of the Administrative Procedure Act?](https://www.yalejreg.com/nc/do-large-language-models-dream-of-the-administrative-procedure-act-by-jack-jones-burcin-unel/)” (Feb. 9, 2026)
- Gilbert Orbea & Emily Froude, “[Determining the Reasonableness of Regulating with AI](https://www.yalejreg.com/nc/determining-the-reasonableness-of-regulating-with-ai-by-gilbert-orbea-emily-froude/)” (Feb. 10, 2026)
- Elliot E.C. Ping, “[Iterative Reasoning, Arbitrary Results: Chain-of-Thought Prompt Engineering for APA Compliance](https://www.yalejreg.com/nc/iterative-reasoning-arbitrary-results-chain-of-thought-prompt-engineering-for-apa-compliance-by-elliot-e-c-ping/)” (Feb. 11, 2026)
- Adam Crews, “[Agencies, Not Courts, Should Develop Administrative Common Law for AI](https://www.yalejreg.com/nc/agencies-not-courts-should-develop-administrative-common-law-for-ai-by-adam-crews/)” (Feb. 11, 2026)
- Reeve T. Bull, “[AI-empowered Regulatory Reform: Spreading the Virginia Model](https://www.yalejreg.com/nc/ai-empowered-regulatory-reform-spreading-the-virginia-model-by-reeve-t-bull/)” (Feb. 12, 2026)
- Jessica Tillipman, “[Abdicated Judgment: AI Tools and the Future of Reasoned Decision-Making in Federal Procurement](https://www.yalejreg.com/nc/abdicated-judgment-ai-tools-and-the-future-of-reasoned-decision-making-in-federal-procurement-by-jessica-tillipman/)” (Feb. 12, 2026)
- Tara Aida, “[Ticking the Boxes: AI and the Notice-and-Comment Process](https://www.yalejreg.com/nc/ticking-the-boxes-ai-and-the-notice-and-comment-process-by-tara-aida/)” (Feb. 13, 2026)
- Joe Tomlinson & Brendan McGurk, “[Artificial Intelligence and Administrative Law: The UK’s Search for a New Framework](https://www.yalejreg.com/nc/artificial-intelligence-and-administrative-law-the-uks-search-for-a-new-framework-by-joe-tomlinson-brendan-mcgurk/)” (Feb. 16, 2026)
- Bridget C.E. Dooling, “[Use Cases, Humans in the Loop, and Other Sleights of Hand](https://www.yalejreg.com/nc/use-cases-humans-in-the-loop-and-other-sleights-of-hand-by-bridget-c-e-dooling/)” (Feb. 16, 2026)
