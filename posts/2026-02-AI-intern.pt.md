# Quando o estagiário vira chefe

In recent years, the use of artificial intelligence systems in public administration has moved from a futuristic promise to an everyday reality. The incorporation of these tools by government agencies is now presented as one of the main drivers of state modernization. There seems to be a growing — sometimes touching — confidence in the idea that computers know what they are doing.

But first, it is worth clarifying what “using artificial intelligence as support” usually means in practice. It generally translates into something like: “We now have an intern who never sleeps, never complains — and who sometimes seems to know more than everyone else.”

In principle, this is great.

This intern drafts memos, organizes data, summarizes reports, classifies risks, and suggests courses of action. Never misses work. Never gets sick. Never goes on strike. Never asks for a raise. For managers under constant budget and deadline pressure, it is practically a divine manifestation in the form of software.

The problem — potential, not inevitable — begins when the intern starts being treated as the boss.

At first, it is “just to help.”
Then, “to speed things up.”
Next, “to standardize.”
And, if no one is paying close attention, it can become “to decide.”

None of this has to happen. But it can happen. And that is why the use of AI by the state always deserves some degree of attention and skepticism.
The “perfect intern” metaphor is misleading because, in the real world, interns exist to learn from those who know more. With AI, the risk is the opposite: public servants begin to learn from the machine — or, more precisely, to repeat what it says, because it works, it is fast, and it “seems reliable.”

Gradually, public administration may turn into a large institutional exercise in Ctrl+C, Ctrl+V — elegant, efficient, and dangerously comfortable.
An uncomfortable question emerges naturally: who is supervising whom?

This is the core of the overreliance problem. AI does not merely replace tasks. If poorly used, it can replace important mental habits: the habit of questioning easy conclusions, revisiting assumptions, sustaining doubt, and disagreeing with recommendations.

This risk grows when automation is combined with staff reductions. Fewer people, more systems. Fewer specialists, more dashboards. The recent experience of the Donald Trump administration, mixing technological enthusiasm with bureaucratic downsizing, showed how seductive this equation can be: swapping brains for software. It works — until it stops working.

Another possible side effect is the dilution of responsibility. When something goes wrong, no one is at fault. The system suggested it. The platform indicated it. The civil servant validated it. The manager approved it. Everyone followed the workflow. Responsibility simply evaporates.

At this point, the metaphor from The Office almost inevitably appears: the episode in which Michael Scott, played by Steve Carell, ignores Dwight (Rainn Wilson) and follows the GPS straight into a lake. The technology did not fail. Human judgment just took a vacation.

Perhaps the greatest challenge of artificial intelligence in the public sector is not technical. It is cultural: resisting the temptation to stop thinking simply because something — or someone — seems to make work easier and faster while producing apparently adequate results.

But do not worry. We will still see many mishaps caused by the misuse of AI. Public managers publishing prompts in official reports, making decisions without later knowing what they decided, citing regulations that do not exist…

All of this will probably make for great stories. The real question is whether we want to tell them as jokes — or as audit reports.